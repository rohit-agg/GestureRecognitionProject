{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Dropout, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from keras.layers import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D, LSTM, ConvLSTM2D, GlobalAveragePooling2D, GlobalAveragePooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import optimizers\n",
    "\n",
    "import random as rn\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python : 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]\n",
      "jupyter : 5.7.2\n",
      "numpy : 1.26.4\n",
      "tensorflow : 2.18.0\n",
      "keras : 3.8.0\n",
      "PIL Image : 10.4.0\n",
      "imageio : 2.33.1\n"
     ]
    }
   ],
   "source": [
    "# Print python, jupyter and all the imported library versions\n",
    "import sys\n",
    "import jupyter_core\n",
    "\n",
    "print(\"python : {0}\".format(sys.version))\n",
    "print(\"jupyter : {0}\".format(jupyter_core.__version__))\n",
    "print(\"numpy : {0}\".format(np.__version__))\n",
    "print(\"tensorflow : {0}\".format(tf.__version__))\n",
    "print(\"keras : {0}\".format(keras.__version__))\n",
    "print(\"PIL Image : {0}\".format(Image.__version__))\n",
    "print(\"imageio : {0}\".format(imageio.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for all the libraries to keep results as consistent as possible\n",
    "\n",
    "np.random.seed(30)\n",
    "rn.seed(30)\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size = 16\n",
      "img_idx = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "x = 25 ; y = 120 ; z = 120\n"
     ]
    }
   ],
   "source": [
    "# Read training and validation doc containing folder names and corresponding label\n",
    "train_doc = np.random.permutation(open('datasets/gesture_recognition/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('datasets/gesture_recognition/val.csv').readlines())\n",
    "\n",
    "#experiment with the batch size\n",
    "batch_size = 16\n",
    "print(\"batch_size =\", batch_size)\n",
    "\n",
    "#create a list of image numbers you want to use for a particular video\n",
    "img_idx = range(3, 28)\n",
    "print(\"img_idx =\", list(img_idx))\n",
    "\n",
    "# Initialize the 3 dimensions of video\n",
    "x = len(img_idx)\n",
    "y = 120\n",
    "z = 120\n",
    "print(\"x =\", x, \"; y =\", y, \"; z =\", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size):\n",
    "    # print('Source path =', source_path, '; batch size =', batch_size)\n",
    "\n",
    "    crop_box = (0, 20, 120, 140)\n",
    "    # print(\"crop_box =\", crop_box)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        random_list = np.random.permutation(folder_list)\n",
    "        # print(\"random_list =\", random_list)\n",
    "\n",
    "        # calculate the number of batches\n",
    "        if (len(folder_list) % batch_size) == 0:\n",
    "            num_batches = int(len(folder_list)/batch_size)\n",
    "        else:\n",
    "            num_batches = (len(folder_list)//batch_size) + 1\n",
    "        # print(\"num_batches =\", num_batches)\n",
    "\n",
    "        # we iterate over the number of batches\n",
    "        for batch in range(num_batches): \n",
    "\n",
    "            # x is the number of images you use for each video, \n",
    "            # (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) \n",
    "\n",
    "            # batch_labels is the one hot representation of the output\n",
    "            batch_labels = np.zeros((batch_size,5))\n",
    "\n",
    "            # iterate over the batch_size\n",
    "            for folder in range(batch_size): \n",
    "\n",
    "                folder_idx = folder + (batch*batch_size)\n",
    "                if folder_idx >= len(folder_list):\n",
    "                    break\n",
    "                \n",
    "                img_details = random_list[folder_idx].strip().split(';')\n",
    "\n",
    "                # read all the images in the folder\n",
    "                imgs = [file for file in os.listdir(source_path+'/'+ img_details[0]) if os.path.isfile(os.path.join(source_path+'/'+ img_details[0], file))] \n",
    "                # print(\"imgs =\", imgs)\n",
    "\n",
    "                # Iterate iver the frames/images of a folder to read them in\n",
    "                for idx,item in enumerate(img_idx): \n",
    "\n",
    "                    image = imageio.imread(source_path+'/'+ img_details[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    img_shape = image.shape\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    if (img_shape[0] == 120) and (img_shape[1] == 160):\n",
    "                        image = image[crop_box[0]:crop_box[2], crop_box[1]:crop_box[3]]\n",
    "                    \n",
    "                    image = np.array(Image.fromarray(image.astype(np.uint8)).resize((y, z))).astype(np.float32)\n",
    "\n",
    "                    batch_data[folder,idx,:,:,0] = image[:,:,0] / 255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = image[:,:,1] / 255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = image[:,:,2] / 255 #normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(img_details[2])] = 1\n",
    "\n",
    "            #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "            yield batch_data, batch_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 50\n",
      "# input_shape = (25, 120, 120, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load the train and validation directory path\n",
    "train_path = 'datasets/gesture_recognition/train'\n",
    "val_path = 'datasets/gesture_recognition/val'\n",
    "\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "\n",
    "# choose the number of epochs\n",
    "num_epochs = 50\n",
    "print ('# epochs =', num_epochs)\n",
    "\n",
    "input_shape = (x,y,z,3)\n",
    "print(\"# input_shape =\", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to draw the accuracy and loss results\n",
    "def visualize_results(model, epochs, results):\n",
    "\n",
    "    accuracy = results['categorical_accuracy']\n",
    "    validation_accuracy = results['val_categorical_accuracy']\n",
    "    \n",
    "    loss = results['loss']\n",
    "    validation_loss = results['val_loss']\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, accuracy, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, validation_accuracy, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy - ' + model)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, validation_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss - ' + model)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model I (Conv3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(32, activation=\"relu\"))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model II (Conv3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(32, activation=\"relu\"))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(256, activation=\"relu\"))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model III (Conv3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(32, activation=\"relu\"))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(256, activation=\"relu\"))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model IV (Conv3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(32, activation=\"relu\"))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(256, activation=\"relu\"))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model V (Conv3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=(3, 3, 3), padding=\"same\", activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv3D(32, kernel_size=(3, 3, 3), padding=\"same\", activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Conv3D(64, kernel_size=(3, 3, 3), padding=\"same\", activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv3D(64, kernel_size=(3, 3, 3), padding=\"same\", activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Conv3D(128, kernel_size=(3, 3, 3), padding=\"same\", activation='relu'))\n",
    "# model.add(Conv3D(128, kernel_size=(3, 3, 3), padding=\"same\", activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(32, activation=\"relu\"))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(256, activation=\"relu\"))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model VI (Conv3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(16, kernel_size=(3, 3, 3), padding=\"same\", activation='relu', input_shape=input_shape))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv3D(16, kernel_size=(3, 3, 3), padding=\"same\", activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=(3, 3, 3), padding=\"same\", activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv3D(32, kernel_size=(3, 3, 3), padding=\"same\", activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(64, kernel_size=(3, 3, 3), padding=\"same\", activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv3D(64, kernel_size=(3, 3, 3), padding=\"same\", activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation=\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(512, activation=\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model VII (Conv3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(16, kernel_size=(3, 3, 3), padding=\"same\", activation='relu', input_shape=input_shape))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv3D(16, kernel_size=(3, 3, 3), padding=\"same\", activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=(3, 3, 3), padding=\"same\", activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv3D(32, kernel_size=(3, 3, 3), padding=\"same\", activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(64, kernel_size=(3, 3, 3), padding=\"same\", activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv3D(64, kernel_size=(3, 3, 3), padding=\"same\", activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# model.add(GlobalAveragePooling3D())\n",
    "# model.add(Dense(128, activation=\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(512, activation=\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model VIII (Time Distributed Conv2D + GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(TimeDistributed(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'), input_shape=input_shape))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "# model.add(TimeDistributed(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'), input_shape=input_shape))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "# model.add(TimeDistributed(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'), input_shape=input_shape))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "# model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
    "# model.add(TimeDistributed(Dense(128, activation=\"relu\")))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(GRU(128))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model IX (Time Distributed Conv2D + ConvLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "model.add(ConvLSTM2D(16, kernel_size = (3, 3), return_sequences=False))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model (Time Distributed Conv2D + GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
    "model.add(TimeDistributed(Dense(128, activation=\"relu\")))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(GRU(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed_8              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_9              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_12             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_13             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_lstm2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">83,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,565</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed_8              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,   │           \u001b[38;5;34m896\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m32\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m120\u001b[0m,   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ \u001b[38;5;34m32\u001b[0m)                    │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_9              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m) │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m) │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_12             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,     │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,     │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_13             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m,     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_lstm2d (\u001b[38;5;33mConvLSTM2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │        \u001b[38;5;34m83,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m2,565\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,565</span> (978.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m250,565\u001b[0m (978.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">248,805</span> (971.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m248,805\u001b[0m (971.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,760</span> (6.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,760\u001b[0m (6.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#write your optimizer\n",
    "optimiser = optimizers.Adam(learning_rate=0.01) \n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and val generators\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model name using current timestamp\n",
    "curr_dt_time = datetime.datetime.now()\n",
    "model_name = 'results/model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "\n",
    "# Check if directory with model name exists\n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "\n",
    "# Create file path pattern\n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "# Prepare checkpoint after every epoch, configure early stopping in case learning is not happening and reducing learning rate on plateau\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto')\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto'),\n",
    "reduceLearningRate = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=3)\n",
    "callbacks_list = [checkpoint, earlyStopping, reduceLearningRate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the steps for both training and validation data\n",
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"batch_size =\", batch_size)\n",
    "print(\"step_per_epoch =\", steps_per_epoch)\n",
    "print(\"validation_steps =\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model by providing the generator\n",
    "history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the accuracy and loss for model\n",
    "visualize_results(\"Model\", num_epochs, history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
